{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 8: Memory Management"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Key Takeaways:\n",
                "- **Session Management** allows agents to maintain multi-turn conversations through various backends (`InMemory`, `Database`, `VertexAI`).\n",
                "- **State Management** provides a \"scratchpad\" for agents to store and update contextual information during a session.\n",
                "- **Long-Term Memory** leverages Retrieval Augmented Generation (RAG) to persist and search knowledge across multiple sessions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Heuristic: *Context is everything.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup and Initialization "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup-cell",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Configuration Loaded:\n",
                        "   Reasoning Engine ID: projects/878018164626/locations/us-central1/reasoningEngines/7485911668015235072\n",
                        "   RAG ID: projects/gen-lang-client-0223183954/locations/us-east1/ragCorpora/4611686018427387904\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from google.adk.sessions import InMemorySessionService, DatabaseSessionService, VertexAiSessionService\n",
                "from google.adk.agents import LlmAgent\n",
                "from google.adk.agents.invocation_context import InvocationContext\n",
                "from google.adk.runners import Runner\n",
                "from google.genai.types import Content, Part\n",
                "from google.adk.memory import InMemoryMemoryService, VertexAiRagMemoryService\n",
                "from google.adk.tools.tool_context import ToolContext\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# --- Configuration ---\n",
                "REASONING_ENGINE_ID = os.getenv(\"REASONING_ENGINE_ID\")\n",
                "RAG_ID = os.getenv(\"RAG_ID\")\n",
                "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
                "LOCATION = os.getenv(\"LOCATION\", \"us-central1\")\n",
                "\n",
                "print(f\"‚úÖ Configuration Loaded:\")\n",
                "print(f\"   Reasoning Engine ID: {REASONING_ENGINE_ID}\")\n",
                "print(f\"   RAG ID: {RAG_ID}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3b013217",
            "metadata": {},
            "source": [
                "## Session Management\n",
                "\n",
                "Session services keep track of each chat conversation. You can choose different backends based on your needs."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f4afcbb3",
            "metadata": {},
            "source": [
                "### 1. In-Memory Session (Development)\n",
                "\n",
                "Suitable for local development and testing where persistence is NOT required."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "in-memory-session",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ InMemorySessionService initialized.\n"
                    ]
                }
            ],
            "source": [
                "session_service = InMemorySessionService()\n",
                "print(\"‚úÖ InMemorySessionService initialized.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "df694e47",
            "metadata": {},
            "source": [
                "### 2. Database Session (Persistent)\n",
                "\n",
                "Suitable for production or development requiring persistent storage across restarts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "db-session",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ DatabaseSessionService initialized with: sqlite+aiosqlite:///./my_agent_data.db\n"
                    ]
                }
            ],
            "source": [
                "# Example using a local SQLite file with aiosqlite for async support:\n",
                "db_url = \"sqlite+aiosqlite:///./my_agent_data.db\"\n",
                "session_service_db = DatabaseSessionService(db_url=db_url)\n",
                "print(f\"‚úÖ DatabaseSessionService initialized with: {db_url}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "67da6f96",
            "metadata": {},
            "source": [
                "### 3. Vertex AI Session (Production)\n",
                "\n",
                "Leverages Google Cloud's Vertex AI infrastructure for scalable session management."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "vertex-ai-session",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ VertexAiSessionService initialized for engine: projects/878018164626/locations/us-central1/reasoningEngines/7485911668015235072\n"
                    ]
                }
            ],
            "source": [
                "if REASONING_ENGINE_ID and PROJECT_ID:\n",
                "    # The app_name used with this service should correspond to the Reasoning Engine ID\n",
                "    REASONING_ENGINE_APP_NAME = REASONING_ENGINE_ID\n",
                "    \n",
                "    session_service_vca = VertexAiSessionService(project=PROJECT_ID, location=LOCATION)\n",
                "    print(f\"‚úÖ VertexAiSessionService initialized for engine: {REASONING_ENGINE_ID}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è REASONING_ENGINE_ID or PROJECT_ID not found in .env. Skipping initialization.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c86caf80",
            "metadata": {},
            "source": [
                "## State Management\n",
                "\n",
                "State allows you to store custom data along with the session."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "95f893f8",
            "metadata": {},
            "source": [
                "### 1. Simple State: `output_key`\n",
                "\n",
                "Automatically capture the agent's last response into the session state."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "simple-state",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initial state: {}\n",
                        "Agent responded.\n",
                        "State after agent run: {'last_greeting': 'Hi there! Nice to meet you. üòä'}\n"
                    ]
                }
            ],
            "source": [
                "# Define an LlmAgent with an output_key.\n",
                "greeting_agent = LlmAgent(\n",
                "    name=\"Greeter\",\n",
                "    model=\"gemini-2.5-flash\",\n",
                "    instruction=\"Generate a short, friendly greeting.\",\n",
                "    output_key=\"last_greeting\"\n",
                ")\n",
                "\n",
                "app_name, user_id, session_id = \"state_app\", \"user1\", \"session1\"\n",
                "session_service = InMemorySessionService()\n",
                "runner = Runner(\n",
                "    agent=greeting_agent,\n",
                "    app_name=app_name,\n",
                "    session_service=session_service\n",
                ")\n",
                "\n",
                "session = await session_service.create_session(\n",
                "    app_name=app_name,\n",
                "    user_id=user_id,\n",
                "    session_id=session_id\n",
                ")\n",
                "\n",
                "print(f\"Initial state: {session.state}\")\n",
                "\n",
                "# Run the agent\n",
                "user_message = Content(parts=[Part(text=\"Hello\")])\n",
                "for event in runner.run(user_id=user_id, session_id=session_id, new_message=user_message):\n",
                "    if event.is_final_response():\n",
                "        print(\"Agent responded.\")\n",
                "\n",
                "# Check updated state - ensure keyword arguments are used\n",
                "updated_session = await session_service.get_session(app_name=app_name, user_id=user_id, session_id=session_id)\n",
                "print(f\"State after agent run: {updated_session.state}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c02d391",
            "metadata": {},
            "source": [
                "### 2. Advanced State: Tool-Based Updates\n",
                "\n",
                "Use tools to update state explicitly during a conversation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "advanced-state",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initial state: {'task_status': 'idle', 'user:login_count': 0}\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
                        "/opt/anaconda3/envs/asd/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:449: UserWarning: [EXPERIMENTAL] feature FeatureName.PROGRESSIVE_SSE_STREAMING is enabled.\n",
                        "  async for event in agen:\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Agent processed login.\n",
                        "State after tool execution: {'task_status': 'active', 'user:login_count': 1, 'user:last_login_ts': 1768061129.6008341}\n"
                    ]
                }
            ],
            "source": [
                "import time\n",
                "\n",
                "def log_user_login(tool_context: ToolContext) -> dict:\n",
                "    \"\"\"Updates the session state upon a user login event.\"\"\"\n",
                "    state = tool_context.state\n",
                "    login_count = state.get(\"user:login_count\", 0) + 1\n",
                "    state[\"user:login_count\"] = login_count\n",
                "    state[\"task_status\"] = \"active\"\n",
                "    state[\"user:last_login_ts\"] = time.time()\n",
                "    return {\"status\": \"success\", \"message\": f\"Login tracked. Logins: {login_count}\"}\n",
                "\n",
                "# Create an agent that uses the login tool\n",
                "login_agent = LlmAgent(\n",
                "    name=\"LoginTracker\",\n",
                "    model=\"gemini-2.5-flash\",\n",
                "    instruction=\"You are a login tracker. When the user says 'login', call the log_user_login tool.\",\n",
                "    tools=[log_user_login]\n",
                ")\n",
                "\n",
                "# Setup session with initial state\n",
                "session_service = InMemorySessionService()\n",
                "app_name, user_id, session_id = \"state_app_tool\", \"user3\", \"session3\"\n",
                "session = await session_service.create_session(\n",
                "    app_name=app_name, \n",
                "    user_id=user_id, \n",
                "    session_id=session_id,\n",
                "    state={\"user:login_count\": 0, \"task_status\": \"idle\"}\n",
                ")\n",
                "\n",
                "print(f\"Initial state: {session.state}\")\n",
                "\n",
                "# Run the agent to trigger the tool\n",
                "runner = Runner(\n",
                "    agent=login_agent,\n",
                "    app_name=app_name,\n",
                "    session_service=session_service\n",
                ")\n",
                "\n",
                "user_message = Content(parts=[Part(text=\"login\")])\n",
                "for event in runner.run(user_id=user_id, session_id=session_id, new_message=user_message):\n",
                "    if event.is_final_response():\n",
                "        print(\"Agent processed login.\")\n",
                "\n",
                "# Check updated state\n",
                "updated_session = await session_service.get_session(app_name=app_name, user_id=user_id, session_id=session_id)\n",
                "print(f\"State after tool execution: {updated_session.state}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Long-Term Memory\n",
                "\n",
                "Memory services provide searchable, persistent knowledge."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. In-Memory Memory (Development)\n",
                "\n",
                "Lost when the application stops."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "in-memory-memory",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ InMemoryMemoryService initialized.\n"
                    ]
                }
            ],
            "source": [
                "memory_service = InMemoryMemoryService()\n",
                "print(\"‚úÖ InMemoryMemoryService initialized.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Vertex AI RAG Memory (Production)\n",
                "\n",
                "Leverages Vertex AI RAG for persistent, searchable memory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "rag-memory",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ VertexAiRagMemoryService initialized for corpus: projects/gen-lang-client-0223183954/locations/us-east1/ragCorpora/4611686018427387904\n"
                    ]
                }
            ],
            "source": [
                "if RAG_ID and PROJECT_ID:\n",
                "    RAG_CORPUS_RESOURCE_NAME = RAG_ID\n",
                "    \n",
                "    memory_service_vca = VertexAiRagMemoryService(\n",
                "        rag_corpus=RAG_CORPUS_RESOURCE_NAME,\n",
                "        similarity_top_k=5,\n",
                "        vector_distance_threshold=0.7\n",
                "    )\n",
                "    print(f\"‚úÖ VertexAiRagMemoryService initialized for corpus: {RAG_ID}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è RAG_ID or PROJECT_ID not found in .env. Skipping initialization.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "Memory and State systems allow your agents to \"remember\" who the user is and what has happened previously. This is crucial for building sophisticated, reliable agentic workflows."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "asd",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
