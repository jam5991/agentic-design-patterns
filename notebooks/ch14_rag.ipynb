{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 14: Retrieval-Augmented Generation (RAG)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Key Takeaways:\n",
                "- **Augmented Knowledge**: RAG enables agents to access and utilize external knowledge bases that they were not trained on.\n",
                "- **Contextual Relevance**: By retrieving relevant information before generating a response, agents can provide more accurate and context-aware answers.\n",
                "- **Simulated Memory**: In this example, we use a service to simulate retrieving documents based on semantic search.\n",
                "- **Tool Integration**: Combining RAG with search tools allows for a powerful research assistant capable of synthesizing internal and external information."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Heuristic: *Connect memory to logic. RAG grounds generation in retrieved facts.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup and Initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "from dotenv import load_dotenv\n",
                "from typing import Optional, Dict, List, Any\n",
                "\n",
                "# Add scripts directory to path to import custom modules\n",
                "PROJECT_ROOT = os.path.dirname(os.getcwd())\n",
                "SCRIPTS_DIR = os.path.join(PROJECT_ROOT, \"scripts\")\n",
                "sys.path.insert(0, SCRIPTS_DIR)\n",
                "\n",
                "# Import our custom ADK implementation and RAG memory service\n",
                "from custom_adk import Agent, google_search\n",
                "from rag_memory import VertexAiRagMemoryService\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "\n",
                "# Verify API key\n",
                "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
                "    print(\"❌ Please set the GOOGLE_API_KEY environment variable.\")\n",
                "else:\n",
                "    print(\"✅ Configuration Loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Initialize RAG Memory Service\n",
                "\n",
                "We setup the connection to our vector database (simulated here) to retrieve relevant chunks of information."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "rag-setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration for RAG\n",
                "RAG_CORPUS_RESOURCE_NAME = os.getenv(\"REASONING_ENGINE_ID\")\n",
                "SIMILARITY_TOP_K = 5\n",
                "VECTOR_DISTANCE_THRESHOLD = 0.7\n",
                "\n",
                "# Initialize the memory service\n",
                "memory_service = VertexAiRagMemoryService(\n",
                "    rag_corpus=RAG_CORPUS_RESOURCE_NAME,\n",
                "    similarity_top_k=SIMILARITY_TOP_K,\n",
                "    vector_distance_threshold=VECTOR_DISTANCE_THRESHOLD\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define Agent\n",
                "\n",
                "We create a Research Assistant agent equipped with the Google Search tool. In a full RAG system, the agent might also have a tool to query the memory service directly, or the memory service might be used to pre-populate context."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "agent-def",
            "metadata": {},
            "outputs": [],
            "source": [
                "search_agent = Agent(\n",
                "    name=\"research_assistant\",\n",
                "    model=\"gemini-2.5-flash\",\n",
                "    instruction=\"\"\"\n",
                "You help users research topics. \n",
                "Use the google_search tool when you need current information from the web.\n",
                "Synthesize the information you find into clear, concise summaries.\n",
                "\"\"\",\n",
                "    tools=[google_search]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Execution Examples\n",
                "\n",
                "### Scenario 1: Basic Retrieval\n",
                "Simulating the retrieval of context relevant to a user query."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-rag-retrieve",
            "metadata": {},
            "outputs": [],
            "source": [
                "user_query = \"What data \"\n",
                "\n",
                "# 1. Retrieve relevant context\n",
                "retrieved_docs = memory_service.retrieve(user_query)\n",
                "\n",
                "# 2. Format context for the agent (demonstration)\n",
                "context_str = \"\\n\\n\".join([f\"Source: {d['source']}\\nContent: {d['content']}\" for d in retrieved_docs])\n",
                "\n",
                "print(f\"--- Constructed Context ---\\n{context_str}\\n---------------------------\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Scenario 2: Agent Execution with Context\n",
                "Now we pass this context to the agent along with the user's question, allowing it to answer based on the retrieved knowledge."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-rag-agent",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Construct the full prompt with context\n",
                "augmented_prompt = f\"\"\"\n",
                "Context Information:\n",
                "{context_str}\n",
                "\n",
                "Question: {user_query}\n",
                "\"\"\"\n",
                "\n",
                "state = {\n",
                "    \"last_user_message\": augmented_prompt\n",
                "}\n",
                "\n",
                "response = search_agent.run(state)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Scenario 3: Using External Tools\n",
                "The agent can also use its tools (Google Search) to find information not present in the RAG corpus."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-search-agent",
            "metadata": {},
            "outputs": [],
            "source": [
                "state_search = {\n",
                "    \"last_user_message\": \"Search for the latest Agentic Design Patterns released in 2025\"\n",
                "}\n",
                "\n",
                "response_search = search_agent.run(state_search)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "This notebook demonstrated the components of a RAG system: a memory service for retrieval and an agent for generation and tool use. By combining these, we create grounded, capable AI assistants."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "asd",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
