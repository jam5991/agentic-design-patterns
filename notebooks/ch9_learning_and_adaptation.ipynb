{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 9: Learning and Adaptation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Key Takeaways:\n",
                "- **Evolutionary Coding** uses LLMs to automatically discover and optimize algorithms through iterative code generation, evaluation, and selection.\n",
                "- **OpenEvolve** is an open-source implementation of evolutionary coding that can evolve entire code files across multiple programming languages.\n",
                "- **Multi-objective Optimization** allows simultaneous optimization of multiple metrics like correctness, performance, and code quality."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Heuristic: *Evolution over manual optimization.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup and Initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import nest_asyncio\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Allow nested event loops (required for OpenEvolve in Jupyter)\n",
                "nest_asyncio.apply()\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# --- Configuration ---\n",
                "PROJECT_ROOT = os.path.dirname(os.getcwd())\n",
                "SCRIPTS_DIR = os.path.join(PROJECT_ROOT, \"scripts\")\n",
                "\n",
                "print(f\"âœ… Configuration Loaded:\")\n",
                "print(f\"   Project Root: {PROJECT_ROOT}\")\n",
                "print(f\"   Scripts Directory: {SCRIPTS_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e623a25d",
            "metadata": {},
            "source": [
                "## OpenEvolve Overview\n",
                "\n",
                "OpenEvolve is an evolutionary coding agent that leverages Large Language Models (LLMs) to automatically optimize and discover algorithms. It implements the key concepts from Google DeepMind's AlphaEvolve system.\n",
                "\n",
                "### Key Components\n",
                "\n",
                "| Component | Description |\n",
                "|-----------|-------------|\n",
                "| **LLM Ensemble** | Uses multiple language models to generate diverse code modifications |\n",
                "| **Prompt Sampler** | Creates context-rich prompts incorporating past programs and scores |\n",
                "| **Evaluator Pool** | Tests generated programs and assigns scores based on defined metrics |\n",
                "| **Program Database** | Stores evolved programs using MAP-Elites algorithm for diversity |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d697b238",
            "metadata": {},
            "source": [
                "## The Evolution Pipeline\n",
                "\n",
                "```\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚  Initial Code   â”‚â”€â”€â”€â”€â–¶â”‚   LLM Mutates   â”‚â”€â”€â”€â”€â–¶â”‚    Evaluate     â”‚\n",
                "â”‚   (Program)     â”‚     â”‚   (Generate)    â”‚     â”‚   (Score)       â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "                                                         â”‚\n",
                "                                                         â–¼\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚  Best Program   â”‚â—€â”€â”€â”€â”€â”‚    Selection    â”‚â—€â”€â”€â”€â”€â”‚ Program Databaseâ”‚\n",
                "â”‚   (Output)      â”‚     â”‚   (Fitness)     â”‚     â”‚   (Archive)     â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "93620694",
            "metadata": {},
            "source": [
                "## Required Files\n",
                "\n",
                "OpenEvolve requires three key files to operate:\n",
                "\n",
                "1. **Initial Program** (`initial_program.py`) - The starting code to evolve\n",
                "2. **Evaluator** (`evaluator.py`) - Defines how to score evolved programs\n",
                "3. **Config** (`config.yaml`) - Evolution parameters and LLM settings"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "044d3ae7",
            "metadata": {},
            "source": [
                "### 1. Initial Program\n",
                "\n",
                "This is the starting point for evolution. Mark sections with `EVOLVE-BLOCK-START` and `EVOLVE-BLOCK-END` comments to indicate which parts can be modified."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "view-initial-program",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the initial program\n",
                "initial_program_path = os.path.join(SCRIPTS_DIR, \"initial_program.py\")\n",
                "\n",
                "with open(initial_program_path, 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "03116ab3",
            "metadata": {},
            "source": [
                "### 2. Evaluator\n",
                "\n",
                "The evaluator defines the fitness function that scores each evolved program. It should return a dictionary of metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "view-evaluator",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the evaluator\n",
                "evaluator_path = os.path.join(SCRIPTS_DIR, \"evaluator.py\")\n",
                "\n",
                "with open(evaluator_path, 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "828c537b",
            "metadata": {},
            "source": [
                "### 3. Configuration\n",
                "\n",
                "The config file controls evolution parameters, LLM settings, and evaluation options."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "view-config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the configuration\n",
                "config_path = os.path.join(SCRIPTS_DIR, \"config.yaml\")\n",
                "\n",
                "with open(config_path, 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "584160e5",
            "metadata": {},
            "source": [
                "## Running Evolution\n",
                "\n",
                "OpenEvolve provides a simple `run_evolution` API that accepts file paths directly:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "openevolve-init",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openevolve import run_evolution\n",
                "\n",
                "# Define file paths\n",
                "initial_program_path = os.path.join(SCRIPTS_DIR, \"initial_program.py\")\n",
                "evaluator_path = os.path.join(SCRIPTS_DIR, \"evaluator.py\")\n",
                "config_path = os.path.join(SCRIPTS_DIR, \"config.yaml\")\n",
                "\n",
                "print(\"ğŸ“ OpenEvolve Files:\")\n",
                "print(f\"   Initial Program: {initial_program_path}\")\n",
                "print(f\"   Evaluator: {evaluator_path}\")\n",
                "print(f\"   Config: {config_path}\")\n",
                "print(\"\\nâœ… Ready to run evolution!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-evolution",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run the evolution process\n",
                "# Note: This requires an LLM API key (e.g., OPENAI_API_KEY or GOOGLE_API_KEY)\n",
                "# In a real scenario, you would run many more iterations\n",
                "\n",
                "result = run_evolution(\n",
                "    initial_program=initial_program_path,\n",
                "    evaluator=evaluator_path,\n",
                "    config=config_path,\n",
                "    iterations=2,  # Small number for demo; use 100+ in production\n",
                "    output_dir=\"../scripts/openevolve_output\"\n",
                ")\n",
                "\n",
                "print(f\"\\nğŸ† Evolution Complete!\")\n",
                "print(f\"Best program metrics:\")\n",
                "for name, value in result.metrics.items():\n",
                "    print(f\"  {name}: {value:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analyzing Results\n",
                "\n",
                "After evolution, you can examine the best program and its improvements:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analyze-results",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the evolved code\n",
                "print(\"ğŸ“ Evolved Program Code:\")\n",
                "print(\"=\" * 50)\n",
                "print(result.best_code)\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Compare metrics with the original\n",
                "print(f\"\\nğŸ“Š Performance Improvement:\")\n",
                "print(f\"  Correctness: {result.metrics.get('correctness', 0):.2%}\")\n",
                "print(f\"  Performance: {result.metrics.get('performance', 0):.2%}\")\n",
                "print(f\"  Overall Fitness: {result.metrics.get('fitness', 0):.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Alternative: Using the Low-Level API\n",
                "\n",
                "For more control, you can use the `OpenEvolve` class directly with a `Config` object:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "low-level-api",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openevolve import OpenEvolve\n",
                "from openevolve.config import Config\n",
                "\n",
                "# Load configuration from YAML file\n",
                "config = Config.from_yaml(os.path.join(SCRIPTS_DIR, \"config.yaml\"))\n",
                "\n",
                "# Initialize the OpenEvolve controller\n",
                "evolve = OpenEvolve(\n",
                "    initial_program_path=os.path.join(SCRIPTS_DIR, \"initial_program.py\"),\n",
                "    evaluation_file=os.path.join(SCRIPTS_DIR, \"evaluator.py\"),\n",
                "    config=config\n",
                ")\n",
                "\n",
                "print(\"âœ… OpenEvolve initialized with Config object!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Key Configuration Options\n",
                "\n",
                "| Parameter | Description | Typical Range |\n",
                "|-----------|-------------|---------------|\n",
                "| `iterations` | Number of evolution cycles | 100-10000 |\n",
                "| `population_size` | Programs maintained per generation | 10-100 |\n",
                "| `temperature` | LLM creativity (higher = more diverse) | 0.5-1.0 |\n",
                "| `mutation_rate` | Probability of code modification | 0.1-0.5 |\n",
                "| `elite_count` | Top programs preserved each generation | 1-5 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Best Practices\n",
                "\n",
                "1. **Start Simple** - Begin with a basic, working implementation\n",
                "2. **Clear Metrics** - Define measurable, unambiguous evaluation criteria\n",
                "3. **Balanced Objectives** - Weight correctness higher than performance initially\n",
                "4. **Checkpointing** - Save progress regularly for long evolution runs\n",
                "5. **Diversity** - Use the MAP-Elites algorithm to avoid local optima"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "Learning and Adaptation through evolutionary coding represents a paradigm shift in algorithm development. Instead of manually optimizing code, you can:\n",
                "\n",
                "- **Define the goal** (evaluation metrics)\n",
                "- **Provide a starting point** (initial program)\n",
                "- **Let evolution discover improvements** (run OpenEvolve)\n",
                "\n",
                "This approach is particularly powerful for complex optimization problems where human intuition may miss novel solutions."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "asd",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
