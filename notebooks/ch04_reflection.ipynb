{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Chapter 4: Reflection"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "key-takeaways",
            "metadata": {},
            "source": [
                "Key Takeaways:\n",
                "- **Reflection** is a pattern where an agent critiques its own past outputs.\n",
                "- It allows for iterative improvement and refinement of responses, similar to a human review process.\n",
                "- It is particularly useful for coding tasks, writing, and complex reasoning where a \"first draft\" might be imperfect.\n",
                "- This pattern often involves a loop of Generation -> Critique -> Refinement."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "heuristic",
            "metadata": {},
            "source": [
                "### Heuristic: *Review your work.*"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup",
            "metadata": {},
            "source": [
                "## Setup and Initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.messages import SystemMessage, HumanMessage\n",
                "\n",
                "# Load environment variables from .env file (for OPENAI_API_KEY)\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "llm-init",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Configuration ---\n",
                "# Check if the API key is set\n",
                "if not os.getenv(\"OPENAI_API_KEY\"):\n",
                "    print(\"Warning: OPENAI_API_KEY not found in .env file. Please add it.\")\n",
                "\n",
                "try:\n",
                "    # Initialize the Chat LLM. We use gpt-4o for better reasoning.\n",
                "    # A lower temperature is used for more deterministic outputs.\n",
                "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
                "    print(f\"Language model initialized: {llm.model_name}\")\n",
                "except Exception as e:\n",
                "    print(f\"Error initializing language model: {e}\")\n",
                "    llm = None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "task-desc",
            "metadata": {},
            "source": [
                "## The Core Task\n",
                "\n",
                "We define a task for the agent: create a Python function `calculate_factorial` with specific requirements (docstring, error handling, edge cases)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "define-task",
            "metadata": {},
            "outputs": [],
            "source": [
                "task_prompt = \"\"\"\n",
                "Your task is to create a Python function named `calculate_factorial`.\n",
                "This function should do the following:\n",
                "1. Accept a single integer `n` as input.\n",
                "2. Calculate its factorial (n!).\n",
                "3. Include a clear docstring explaining what the function does.\n",
                "4. Handle edge cases: The factorial of 0 is 1.\n",
                "5. Handle invalid input: Raise a ValueError if the input is a negative number.\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "reflection-loop-header",
            "metadata": {},
            "source": [
                "## The Reflection Loop\n",
                "\n",
                "We implement a loop `run_reflection_loop` which:\n",
                "1.  **Generates** initial code (or refines it in subsequent steps).\n",
                "2.  **Reflects** on the code by acting as a reviewer (critique).\n",
                "3.  **Refines** the code based on the critique.\n",
                "4.  Stops if the critique says \"CODE_IS_PERFECT\" or reaches max iterations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "reflection-func",
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_reflection_loop():\n",
                "    \"\"\"\n",
                "    Demonstrates a multi-step AI reflection loop to progressively improve a Python function.\n",
                "    \"\"\"\n",
                "    if not llm:\n",
                "        print(\"LLM not initialized. Skipping execution.\")\n",
                "        return\n",
                "\n",
                "    max_iterations = 3\n",
                "    current_code = \"\"\n",
                "    # We will build a conversation history to provide context in each step.\n",
                "    message_history = [HumanMessage(content=task_prompt)]\n",
                "\n",
                "    for i in range(max_iterations):\n",
                "        print(\"\\n\" + \"=\"*25 + f\" REFLECTION LOOP: ITERATION {i + 1} \" + \"=\"*25)\n",
                "\n",
                "        # --- 1. GENERATE / REFINE STAGE ---\n",
                "        # In the first iteration, it generates. In subsequent iterations, it refines.\n",
                "        if i == 0:\n",
                "            print(\"\\n>>> STAGE 1: GENERATING initial code...\")\n",
                "            # The first message is just the task prompt.\n",
                "            response = llm.invoke(message_history)\n",
                "            current_code = response.content\n",
                "        else:\n",
                "            print(\"\\n>>> STAGE 1: REFINING code based on previous critique...\")\n",
                "            # The message history now contains the task, the last code, and the last critique.\n",
                "            # We instruct the model to apply the critiques.\n",
                "            message_history.append(HumanMessage(content=\"Please refine the code using the critiques provided.\"))\n",
                "            response = llm.invoke(message_history)\n",
                "            current_code = response.content\n",
                "\n",
                "        print(\"\\n--- Generated Code (v\" + str(i + 1) + \") ---\\n\" + current_code)\n",
                "        message_history.append(response)  # Add the generated code to history\n",
                "\n",
                "        # --- 2. REFLECT STAGE ---\n",
                "        print(\"\\n>>> STAGE 2: REFLECTING on the generated code...\")\n",
                "        \n",
                "        # Create a specific prompt for the reflector agent.\n",
                "        # This asks the model to act as a senior code reviewer.\n",
                "        reflector_prompt = [\n",
                "            SystemMessage(content=\"\"\"\n",
                "You are a senior software engineer and an expert in Python.\n",
                "Your role is to perform a meticulous code review.\n",
                "Critically evaluate the provided Python code based on the original task requirements.\n",
                "Look for bugs, style issues, missing edge cases, and areas for improvement.\n",
                "If the code is perfect and meets all requirements, respond with the single phrase 'CODE_IS_PERFECT'.\n",
                "Otherwise, provide a bulleted list of your critiques.\n",
                "\"\"\"),\n",
                "            HumanMessage(content=f\"Original Task:\\n{task_prompt}\\n\\nCode to Review:\\n{current_code}\")\n",
                "        ]\n",
                "\n",
                "        critique_response = llm.invoke(reflector_prompt)\n",
                "        critique = critique_response.content\n",
                "\n",
                "        # --- 3. STOPPING CONDITION ---\n",
                "        if \"CODE_IS_PERFECT\" in critique:\n",
                "            print(\"\\n--- Critique ---\\nNo further critiques found. The code is satisfactory.\")\n",
                "            break\n",
                "        \n",
                "        print(\"\\n--- Critique ---\\n\" + critique)\n",
                "\n",
                "        # Add the critique to the history for the next refinement loop.\n",
                "        message_history.append(HumanMessage(content=f\"Critique of the previous code:\\n{critique}\"))\n",
                "\n",
                "    print(\"\\n\" + \"=\"*30 + \" FINAL RESULT \" + \"=\"*30)\n",
                "    print(\"\\nFinal refined code after the reflection process:\\n\")\n",
                "    print(current_code)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "execution",
            "metadata": {},
            "source": [
                "## Execution\n",
                "\n",
                "Run the reflection loop to see the agent improve its code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-execution",
            "metadata": {},
            "outputs": [],
            "source": [
                "run_reflection_loop()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "This loop helps ensure higher quality outputs by forcing the model to re-evaluate its own work against the requirements before considering the task complete."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "asd",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
