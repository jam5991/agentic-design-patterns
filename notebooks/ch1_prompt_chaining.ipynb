{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "fdbc1ada",
            "metadata": {},
            "source": [
                "# Chapter 1: Prompt Chaining"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e2570706",
            "metadata": {},
            "source": [
                "Key Takeaways: \n",
                "- Prompt Chaining breaks down complex tasks into a sequence of smaller, focused steps.\n",
                "- This is occasionally known as the Pipeline pattern.\n",
                "- Each step in a chain involves an LLM call or processing logic, using the output of the\n",
                "previous step as input.\n",
                "- This pattern improves the reliability and manageability of complex interactions with\n",
                "language models.\n",
                "- Frameworks like LangChain/LangGraph, and Google ADK provide robust tools to\n",
                "define, manage, and execute these multi-step sequences."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-header",
            "metadata": {},
            "source": [
                "## Setup and Initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "64cb003d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/envs/asd/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
                        "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "# Make sure your OPENAI_API_KEY is set in the .env file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "llm-init",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the Language Model\n",
                "llm = ChatOpenAI(temperature=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pattern1-header",
            "metadata": {},
            "source": [
                "## Pattern 1: Information Processing Workflows\n",
                "\n",
                "This pattern demonstrates processing raw information through multiple transformations. We'll simulate extracting content from a URL, summarizing it, extracting entities, searching a knowledge base, and generating a final report.\n",
                "\n",
                "**Use Case**: Document analysis and reporting pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "8d68c1b8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pattern 1: Information Processing Workflows\n",
                "# 5-step chain: extract text -> summarize -> extract entities -> search KB -> generate report\n",
                "\n",
                "# Step 1: Extract text content (simulated)\n",
                "prompt_extract_text = ChatPromptTemplate.from_template(\n",
                "    \"Extract and clean the main text content from this document:\\n\\n{raw_content}\"\n",
                ")\n",
                "\n",
                "# Step 2: Summarize the cleaned text\n",
                "prompt_summarize = ChatPromptTemplate.from_template(\n",
                "    \"Provide a concise summary of the following text (2-3 sentences):\\n\\n{cleaned_text}\"\n",
                ")\n",
                "\n",
                "# Step 3: Extract entities\n",
                "prompt_extract_entities = ChatPromptTemplate.from_template(\n",
                "    \"Extract key entities (names, dates, locations, organizations) from this text in JSON format:\\n\\n{text}\"\n",
                ")\n",
                "\n",
                "# Step 4: Search knowledge base (simulated with contextual query)\n",
                "prompt_search_kb = ChatPromptTemplate.from_template(\n",
                "    \"Based on these entities: {entities}, generate 2-3 relevant search queries for a knowledge base.\"\n",
                ")\n",
                "\n",
                "# Step 5: Generate final report\n",
                "prompt_generate_report = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Generate a comprehensive report incorporating:\n",
                "    \n",
                "Summary: {summary}\n",
                "Key Entities: {entities}\n",
                "Related Searches: {searches}\n",
                "\n",
                "Format the report in a professional manner with sections.\"\"\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0fc4b9b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build the chain\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "\n",
                "parser = StrOutputParser()\n",
                "\n",
                "# Step 1: Extract cleaned text\n",
                "extract_chain = prompt_extract_text | llm | parser\n",
                "\n",
                "# Step 2: Summarize the cleaned text\n",
                "summarize_chain = prompt_summarize | llm | parser\n",
                "\n",
                "# Step 3: Extract entities\n",
                "entities_chain = prompt_extract_entities | llm | parser\n",
                "\n",
                "# Step 4: Generate search queries\n",
                "search_chain = prompt_search_kb | llm | parser\n",
                "\n",
                "# Full information processing workflow using proper Runnables\n",
                "info_workflow = (\n",
                "    # First, extract cleaned text and pass through the raw_content\n",
                "    RunnablePassthrough.assign(\n",
                "        cleaned_text=extract_chain\n",
                "    )\n",
                "    # Then generate summary and entities based on cleaned_text\n",
                "    | RunnablePassthrough.assign(\n",
                "        summary=lambda x: summarize_chain.invoke({\"cleaned_text\": x[\"cleaned_text\"]}),\n",
                "        entities=lambda x: entities_chain.invoke({\"text\": x[\"cleaned_text\"]})\n",
                "    )\n",
                "    # Then generate searches based on entities\n",
                "    | RunnablePassthrough.assign(\n",
                "        searches=lambda x: search_chain.invoke({\"entities\": x[\"entities\"]})\n",
                "    )\n",
                "    # Finally generate the report using all the collected information\n",
                "    | prompt_generate_report\n",
                "    | llm\n",
                "    | parser\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d887f9de",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== PATTERN 1: Information Processing Workflow ===\n",
                        "**Report on Tesla Inc.'s New Gigafactory in Austin, Texas**\n",
                        "\n",
                        "**Summary:**\n",
                        "On March 15, 2024, Tesla Inc. announced the unveiling of a new Gigafactory in Austin, Texas. The facility is set to produce 500,000 electric vehicles annually and provide jobs for over 10,000 workers. The announcement was made during a press conference attended by Texas Governor Greg Abbott and Austin Mayor Kirk Watson.\n",
                        "\n",
                        "**Key Entities:**\n",
                        "- **Organization:** Tesla Inc.\n",
                        "- **Date:** March 15, 2024\n",
                        "- **Location:** Austin, Texas\n",
                        "- **Persons:** Elon Musk, Greg Abbott, Kirk Watson\n",
                        "- **Facility:** Gigafactory\n",
                        "- **Production Capacity:** 500,000 electric vehicles annually\n",
                        "- **Number of Employees:** Over 10,000\n",
                        "\n",
                        "**Related Searches:**\n",
                        "1. **Production Capacity:** The production capacity of Tesla Inc.'s Gigafactory in Austin, Texas is 500,000 electric vehicles annually.\n",
                        "2. **Key Persons:** The key persons involved in the operations of Tesla Inc.'s Gigafactory in Austin, Texas include Elon Musk, Greg Abbott, and Kirk Watson.\n",
                        "3. **Number of Employees:** Over 10,000 employees work at Tesla Inc.'s Gigafactory in Austin, Texas.\n",
                        "\n",
                        "**Conclusion:**\n",
                        "The unveiling of Tesla Inc.'s new Gigafactory in Austin, Texas marks a significant milestone for the company's expansion in the electric vehicle market. With a production capacity of 500,000 vehicles per year and over 10,000 jobs created, the Gigafactory is poised to make a substantial impact on the local economy and the automotive industry as a whole.\n"
                    ]
                }
            ],
            "source": [
                "# Execute the workflow\n",
                "sample_document = \"\"\"Tesla Inc. announced on March 15, 2024, that CEO Elon Musk will unveil \n",
                "the company's new Gigafactory in Austin, Texas. The facility will produce 500,000 electric \n",
                "vehicles annually and employ over 10,000 workers. The announcement came during a press \n",
                "conference attended by Texas Governor Greg Abbott and Austin Mayor Kirk Watson.\"\"\"\n",
                "\n",
                "result = info_workflow.invoke({\"raw_content\": sample_document})\n",
                "print(\"\\n=== PATTERN 1: Information Processing Workflow ===\")\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pattern2-header",
            "metadata": {},
            "source": [
                "## Pattern 2: Complex Query Answering\n",
                "\n",
                "This pattern breaks down complex questions into sub-questions, researches each independently, and synthesizes a comprehensive answer.\n",
                "\n",
                "**Use Case**: Multi-faceted research questions requiring decomposition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "pattern2-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== PATTERN 2: Complex Query Answering ===\n",
                        "The main causes of the stock market crash in 1929, also known as Black Tuesday, were a combination of economic, political, and social factors. The overvaluation of stocks due to speculative buying on margin, the Federal Reserve's raising of interest rates, and the Smoot-Hawley Tariff Act all contributed to the collapse of stock prices. Additionally, a culture of excessive risk-taking and speculation fueled by media and popular culture played a role in the crash.\n",
                        "\n",
                        "In response to the crash, the U.S. government took immediate action to stabilize the economy and restore confidence in the financial system. The Emergency Banking Act provided federal assistance to struggling banks, while the Reconstruction Finance Corporation offered loans to stimulate economic activity. Longer-term policy changes included the Securities Act of 1933 and the Securities Exchange Act of 1934 to regulate the securities industry, the Glass-Steagall Act of 1933 to separate commercial and investment banking activities, and the Social Security Act of 1935 to provide a safety net for Americans.\n",
                        "\n",
                        "Overall, the government's response to the 1929 stock market crash involved a combination of immediate measures to stabilize the economy and longer-term policy changes to prevent future economic crises. These actions helped restore confidence in the financial system and laid the groundwork for a more stable and regulated financial industry in the years to come.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_core.runnables import RunnablePassthrough\n",
                "\n",
                "# Step 1: Identify core sub-questions\n",
                "prompt_identify_subqs = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Break down this complex question into 2-3 specific sub-questions:\n",
                "    \n",
                "Question: {query}\n",
                "\n",
                "Provide the sub-questions as a numbered list.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 2: Research the causes\n",
                "prompt_research_causes = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Provide detailed information about the causes of the 1929 stock market crash.\n",
                "    Include economic, political, and social factors. (3-4 paragraphs)\"\"\"\n",
                ")\n",
                "\n",
                "# Step 3: Research government response\n",
                "prompt_research_response = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Describe how the U.S. government responded to the 1929 stock market crash.\n",
                "    Include both immediate actions and longer-term policy changes. (3-4 paragraphs)\"\"\"\n",
                ")\n",
                "\n",
                "# Step 4: Synthesize the information\n",
                "prompt_synthesize = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Based on the following research, provide a comprehensive answer to the original question:\n",
                "\n",
                "Original Question: {original_query}\n",
                "\n",
                "Sub-questions identified:\n",
                "{subquestions}\n",
                "\n",
                "Research on Causes:\n",
                "{causes_info}\n",
                "\n",
                "Research on Government Response:\n",
                "{response_info}\n",
                "\n",
                "Synthesize this into a coherent, well-structured answer.\"\"\"\n",
                ")\n",
                "\n",
                "# Build the complex query chain using RunnablePassthrough\n",
                "subq_chain = prompt_identify_subqs | llm | parser\n",
                "causes_chain = prompt_research_causes | llm | parser\n",
                "response_chain = prompt_research_response | llm | parser\n",
                "\n",
                "complex_query_chain = (\n",
                "    # Step 1: Keep original query and identify sub-questions\n",
                "    RunnablePassthrough.assign(\n",
                "        original_query=lambda x: x[\"query\"],\n",
                "        subquestions=subq_chain\n",
                "    )\n",
                "    # Step 2 & 3: Add research results (these don't depend on previous steps in this case)\n",
                "    | RunnablePassthrough.assign(\n",
                "        causes_info=lambda x: causes_chain.invoke({}),\n",
                "        response_info=lambda x: response_chain.invoke({})\n",
                "    )\n",
                "    # Step 4: Synthesize everything into final answer\n",
                "    | prompt_synthesize\n",
                "    | llm\n",
                "    | parser\n",
                ")\n",
                "\n",
                "# Execute\n",
                "query = \"What were the main causes of the stock market crash in 1929, and how did government policy respond?\"\n",
                "result = complex_query_chain.invoke({\"query\": query})\n",
                "print(\"\\n=== PATTERN 2: Complex Query Answering ===\")\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pattern3-header",
            "metadata": {},
            "source": [
                "## Pattern 3: Data Extraction and Transformation\n",
                "\n",
                "This pattern demonstrates iterative extraction and validation, with conditional re-extraction for missing or malformed data.\n",
                "\n",
                "**Use Case**: Converting unstructured documents to structured data with validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "pattern3-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== PATTERN 3: Data Extraction and Transformation ===\n",
                        "\n",
                        "First extraction attempt:\n",
                        "{\n",
                        "  \"invoice_number\": \"12345\",\n",
                        "  \"date\": \"2024-01-15\",\n",
                        "  \"customer_name\": \"John Smith\",\n",
                        "  \"customer_address\": \"123 Main Street, New York, NY 10001\",\n",
                        "  \"total_amount\": \"$2,727\"\n",
                        "}\n",
                        "\n",
                        "=== Final Validated Data ===\n",
                        "{\n",
                        "  \"invoice_number\": \"12345\",\n",
                        "  \"date\": \"2024-01-15\",\n",
                        "  \"customer_name\": \"John Smith\",\n",
                        "  \"customer_address\": \"123 Main Street, New York, NY 10001\",\n",
                        "  \"total_amount\": \"$2,727\"\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "# Pattern 3: Data Extraction and Transformation\n",
                "# Iterative extraction with validation and retry logic\n",
                "\n",
                "import json\n",
                "\n",
                "# Step 1: Initial extraction attempt\n",
                "prompt_extract_fields = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Extract the following fields from this invoice document and return as JSON:\n",
                "- invoice_number\n",
                "- date\n",
                "- customer_name\n",
                "- customer_address\n",
                "- total_amount\n",
                "\n",
                "Invoice text:\n",
                "{invoice_text}\n",
                "\n",
                "Return only valid JSON, no additional text.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 2: Validation and conditional re-extraction\n",
                "def validate_and_retry(invoice_text):\n",
                "    extraction_chain = prompt_extract_fields | llm | parser\n",
                "    \n",
                "    # First attempt\n",
                "    result = extraction_chain.invoke({\"invoice_text\": invoice_text})\n",
                "    print(\"\\nFirst extraction attempt:\")\n",
                "    print(result)\n",
                "    \n",
                "    try:\n",
                "        data = json.loads(result)\n",
                "        required_fields = [\"invoice_number\", \"date\", \"customer_name\", \"customer_address\", \"total_amount\"]\n",
                "        missing = [f for f in required_fields if f not in data or not data[f]]\n",
                "        \n",
                "        if missing:\n",
                "            # Retry with specific instructions for missing fields\n",
                "            print(f\"\\nMissing fields detected: {missing}\")\n",
                "            print(\"Attempting re-extraction...\")\n",
                "            \n",
                "            retry_prompt = ChatPromptTemplate.from_template(\n",
                "                \"\"\"The previous extraction was missing these fields: {missing_fields}\n",
                "                \n",
                "Please carefully re-examine the invoice and extract these specific fields:\n",
                "{missing_fields}\n",
                "\n",
                "Previous extraction:\n",
                "{previous_result}\n",
                "\n",
                "Invoice text:\n",
                "{invoice_text}\n",
                "\n",
                "Return complete JSON with all fields.\"\"\"\n",
                "            )\n",
                "            \n",
                "            retry_chain = retry_prompt | llm | parser\n",
                "            result = retry_chain.invoke({\n",
                "                \"missing_fields\": \", \".join(missing),\n",
                "                \"previous_result\": result,\n",
                "                \"invoice_text\": invoice_text\n",
                "            })\n",
                "            print(\"\\nRetry extraction result:\")\n",
                "            print(result)\n",
                "            \n",
                "        return result\n",
                "    except json.JSONDecodeError:\n",
                "        print(\"\\nInvalid JSON format, requesting reformatting...\")\n",
                "        return result\n",
                "\n",
                "# Sample invoice\n",
                "invoice = \"\"\"ACME Corp Invoice\n",
                "Invoice #12345\n",
                "Date: 2024-01-15\n",
                "\n",
                "Bill To:\n",
                "John Smith\n",
                "123 Main Street\n",
                "New York, NY 10001\n",
                "\n",
                "Items:\n",
                "- Laptop Computer (Qty: 2) @ $1,200 = $2,400\n",
                "- Wireless Mouse (Qty: 5) @ $25 = $125\n",
                "\n",
                "Subtotal: $2,525\n",
                "Tax (8%): $202\n",
                "TOTAL: $2,727\n",
                "\"\"\"\n",
                "\n",
                "print(\"=== PATTERN 3: Data Extraction and Transformation ===\")\n",
                "final_data = validate_and_retry(invoice)\n",
                "print(\"\\n=== Final Validated Data ===\")\n",
                "print(final_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pattern4-header",
            "metadata": {},
            "source": [
                "## Pattern 4: Content Generation Workflows\n",
                "\n",
                "This pattern demonstrates progressive content creation: ideation → selection → outlining → drafting → refinement.\n",
                "\n",
                "**Use Case**: Structured content creation for articles, reports, or documentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "pattern4-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== PATTERN 4: Content Generation Workflow ===\n",
                        "\n",
                        "=== Generated Ideas ===\n",
                        "1. \"The Future of Healthcare: How Artificial Intelligence is Revolutionizing Patient Care\"\n",
                        "   - Explore the ways in which AI is transforming the healthcare industry, from personalized treatment plans to predictive analytics for early disease detection.\n",
                        "\n",
                        "2. \"Ethical Considerations in AI Healthcare: Balancing Innovation with Patient Privacy\"\n",
                        "   - Discuss the ethical dilemmas surrounding the use of AI in healthcare, including concerns about data security, patient consent, and bias in algorithms.\n",
                        "\n",
                        "3. \"From Diagnosis to Treatment: How AI is Streamlining Healthcare Processes\"\n",
                        "   - Highlight the efficiency improvements brought about by AI in healthcare, such as faster diagnosis, automated administrative tasks, and optimized treatment plans.\n",
                        "\n",
                        "4. \"The Role of AI in Mental Health: Breaking Down Barriers to Access and Stigma\"\n",
                        "   - Examine how AI is being used to improve mental health care, including virtual therapy sessions, chatbots for support, and predictive models for early intervention.\n",
                        "\n",
                        "5. \"The Future of Medical Research: How AI is Accelerating Discoveries and Breakthroughs\"\n",
                        "   - Explore the ways in which AI is revolutionizing medical research, from drug discovery to genomics, and the potential impact on developing new treatments and cures.\n",
                        "\n",
                        "=== Selected Topic ===\n",
                        "\"The Future of Healthcare: How Artificial Intelligence is Revolutionizing Patient Care\"\n",
                        "\n",
                        "This topic is engaging and timely as it explores the transformative impact of AI on patient care, highlighting advancements in personalized treatment plans and early disease detection. With the increasing integration of AI in healthcare, understanding its potential benefits and implications is crucial for both healthcare professionals and patients.\n",
                        "\n",
                        "=== Outline ===\n",
                        "I. Introduction\n",
                        "    A. Brief overview of the current state of healthcare\n",
                        "    B. Introduction to the role of artificial intelligence in revolutionizing patient care\n",
                        "    C. Thesis statement: AI is transforming patient care through personalized treatment plans and early disease detection\n",
                        "\n",
                        "II. Personalized Treatment Plans\n",
                        "    A. Explanation of how AI analyzes patient data to create personalized treatment plans\n",
                        "    B. Benefits of personalized treatment plans, such as improved outcomes and reduced healthcare costs\n",
                        "    C. Case studies or examples of successful implementation of AI in creating personalized treatment plans\n",
                        "\n",
                        "III. Early Disease Detection\n",
                        "    A. Overview of how AI is used to analyze medical images and data for early disease detection\n",
                        "    B. Importance of early disease detection in improving patient outcomes\n",
                        "    C. Examples of AI technologies that have been successful in early disease detection, such as AI-powered diagnostic tools\n",
                        "\n",
                        "IV. Ethical and Legal Implications\n",
                        "    A. Discussion of the ethical considerations surrounding the use of AI in healthcare\n",
                        "    B. Explanation of legal implications and regulations related to AI in patient care\n",
                        "    C. Consideration of potential challenges and limitations of AI in healthcare\n",
                        "\n",
                        "V. Conclusion\n",
                        "    A. Recap of the transformative impact of AI on patient care\n",
                        "    B. Call to action for healthcare professionals and patients to stay informed and engaged in the future of healthcare\n",
                        "    C. Final thoughts on the potential of AI to revolutionize patient care and improve healthcare outcomes\n",
                        "\n",
                        "=== Introduction Draft ===\n",
                        "The current state of healthcare is facing numerous challenges, including rising costs, inefficiencies, and disparities in access to care. However, the emergence of artificial intelligence (AI) has the potential to revolutionize patient care by providing personalized treatment plans and early disease detection. AI has the ability to analyze vast amounts of patient data to create tailored treatment plans that take into account individual characteristics and medical history. This personalized approach can lead to improved outcomes, reduced healthcare costs, and a more efficient healthcare system overall.\n",
                        "\n",
                        "In addition to personalized treatment plans, AI is also being used to detect diseases at an earlier stage, when they are more treatable. By analyzing medical images and data, AI can identify subtle patterns and abnormalities that may go unnoticed by human healthcare providers. Early disease detection is crucial in improving patient outcomes and increasing the chances of successful treatment. AI-powered diagnostic tools have already shown promising results in detecting diseases such as cancer, heart disease, and neurological disorders. The potential of AI to transform patient care is vast, and its impact on healthcare is only beginning to be realized.\n",
                        "\n",
                        "=== Refined Introduction ===\n",
                        "The healthcare industry is currently facing a multitude of challenges, including escalating costs, inefficiencies, and disparities in access to care. However, the emergence of artificial intelligence (AI) holds the potential to revolutionize patient care by offering personalized treatment plans and early disease detection. AI has the capability to analyze extensive amounts of patient data to develop tailored treatment plans that consider individual characteristics and medical history. This personalized approach has the potential to enhance outcomes, lower healthcare costs, and create a more efficient healthcare system overall.\n",
                        "\n",
                        "In addition to personalized treatment plans, AI is also being utilized for early disease detection, when conditions are more manageable. By examining medical images and data, AI can pinpoint subtle patterns and abnormalities that may be overlooked by human healthcare providers. Early disease detection is crucial for improving patient outcomes and increasing the likelihood of successful treatment. AI-powered diagnostic tools have already demonstrated promising results in detecting diseases such as cancer, heart disease, and neurological disorders. The potential of AI to revolutionize patient care is vast, and its impact on healthcare is just beginning to be realized.\n"
                    ]
                }
            ],
            "source": [
                "# Pattern 4: Content Generation Workflows\n",
                "# 5-step chain: ideas -> selection -> outline -> drafting -> refinement\n",
                "\n",
                "# Step 1: Generate topic ideas\n",
                "prompt_generate_ideas = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Generate 5 engaging blog post topic ideas about: {interest}\n",
                "    \n",
                "Format: numbered list with brief description for each.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 2: Auto-select best idea (or could be user selection)\n",
                "prompt_select_topic = ChatPromptTemplate.from_template(\n",
                "    \"\"\"From these topic ideas, select the most engaging and timely one:\n",
                "\n",
                "{ideas}\n",
                "\n",
                "Return only the selected topic title and a brief rationale.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 3: Create detailed outline\n",
                "prompt_create_outline = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Create a detailed outline for a blog post on this topic:\n",
                "\n",
                "{selected_topic}\n",
                "\n",
                "Include:\n",
                "- Introduction\n",
                "- 3-4 main points with sub-points\n",
                "- Conclusion\"\"\"\n",
                ")\n",
                "\n",
                "# Step 4: Draft sections\n",
                "prompt_draft_section = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Write a draft section for this part of the outline:\n",
                "\n",
                "Section: {section}\n",
                "\n",
                "Full outline for context:\n",
                "{full_outline}\n",
                "\n",
                "Previous sections:\n",
                "{previous_content}\n",
                "\n",
                "Write 2-3 paragraphs for this section.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 5: Refine complete draft\n",
                "prompt_refine = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Review and refine this blog post draft for coherence, tone, and grammar:\n",
                "\n",
                "{complete_draft}\n",
                "\n",
                "Provide the refined version with improvements.\"\"\"\n",
                ")\n",
                "\n",
                "# Build content generation workflow\n",
                "ideas_chain = prompt_generate_ideas | llm | parser\n",
                "select_chain = prompt_select_topic | llm | parser\n",
                "outline_chain = prompt_create_outline | llm | parser\n",
                "section_chain = prompt_draft_section | llm | parser\n",
                "refine_chain = prompt_refine | llm | parser\n",
                "\n",
                "# Execute workflow (simplified version - full version would iterate through sections)\n",
                "def content_generation_workflow(interest):\n",
                "    # Generate and select topic\n",
                "    ideas = ideas_chain.invoke({\"interest\": interest})\n",
                "    print(\"\\n=== Generated Ideas ===\")\n",
                "    print(ideas)\n",
                "    \n",
                "    selected = select_chain.invoke({\"ideas\": ideas})\n",
                "    print(\"\\n=== Selected Topic ===\")\n",
                "    print(selected)\n",
                "    \n",
                "    outline = outline_chain.invoke({\"selected_topic\": selected})\n",
                "    print(\"\\n=== Outline ===\")\n",
                "    print(outline)\n",
                "    \n",
                "    # Draft first section\n",
                "    intro = section_chain.invoke({\n",
                "        \"section\": \"Introduction\",\n",
                "        \"full_outline\": outline,\n",
                "        \"previous_content\": \"\"\n",
                "    })\n",
                "    print(\"\\n=== Introduction Draft ===\")\n",
                "    print(intro)\n",
                "    \n",
                "    # For brevity, we'll refine just the intro\n",
                "    refined = refine_chain.invoke({\"complete_draft\": intro})\n",
                "    print(\"\\n=== Refined Introduction ===\")\n",
                "    print(refined)\n",
                "    \n",
                "    return refined\n",
                "\n",
                "print(\"=== PATTERN 4: Content Generation Workflow ===\")\n",
                "result = content_generation_workflow(\"artificial intelligence in healthcare\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pattern5-header",
            "metadata": {},
            "source": [
                "## Pattern 5: Conversational Agents with State\n",
                "\n",
                "This pattern maintains conversation context by building each turn's prompt with accumulated history.\n",
                "\n",
                "**Use Case**: Chatbots, virtual assistants, multi-turn dialogues"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "pattern5-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== PATTERN 5: Conversational Agent with State ===\n",
                        "\n",
                        "--- Turn 1 ---\n",
                        "User: Hi, I'd like to book a doctor's appointment\n",
                        "Agent: Hi there! I'd be happy to help you book a doctor's appointment. Can you please provide me with some more information such as the type of doctor you need to see, your preferred date and time, and any specific location preferences? Let me know so I can assist you further.\n",
                        "\n",
                        "--- Turn 2 ---\n",
                        "User: I prefer next Tuesday afternoon\n",
                        "Agent: Hi there! Thank you for letting me know that you prefer next Tuesday afternoon for your doctor's appointment. I will do my best to accommodate that request. Can you please provide me with the type of doctor you need to see and any specific location preferences? This will help me find the best available option for you. Thank you for your cooperation!\n",
                        "\n",
                        "--- Turn 3 ---\n",
                        "User: Yes, that works. My name is Sarah Johnson\n",
                        "Agent: Great to meet you, Sarah Johnson! I'm glad to hear that the appointment time works for you. Now that I have your name, is there anything else you'd like to share or ask about your upcoming doctor's appointment? Feel free to let me know if you have any specific preferences or questions. I'm here to help make your appointment as smooth as possible!\n",
                        "\n",
                        "=== Final Conversation State ===\n",
                        "Total turns: 3\n"
                    ]
                }
            ],
            "source": [
                "# Pattern 5: Conversational Agents with State\n",
                "# Maintain context across multiple conversation turns\n",
                "\n",
                "class ConversationalAgent:\n",
                "    def __init__(self):\n",
                "        self.conversation_state = {\n",
                "            \"history\": [],\n",
                "            \"user_info\": {},\n",
                "            \"intent_stack\": []\n",
                "        }\n",
                "        \n",
                "        # Prompt for intent and entity extraction\n",
                "        self.intent_prompt = ChatPromptTemplate.from_template(\n",
                "            \"\"\"Analyze this user message and extract:\n",
                "1. Primary intent (e.g., 'book_appointment', 'ask_question', 'provide_info')\n",
                "2. Key entities (names, dates, locations, etc.)\n",
                "\n",
                "User message: {user_message}\n",
                "\n",
                "Conversation history: {history}\n",
                "\n",
                "Return as JSON with 'intent' and 'entities' fields.\"\"\"\n",
                "        )\n",
                "        \n",
                "        # Prompt for response generation\n",
                "        self.response_prompt = ChatPromptTemplate.from_template(\n",
                "            \"\"\"Generate a helpful response based on:\n",
                "\n",
                "User message: {user_message}\n",
                "Detected intent: {intent_info}\n",
                "Conversation history: {history}\n",
                "User profile: {user_info}\n",
                "\n",
                "Be conversational, helpful, and reference previous context when relevant.\"\"\"\n",
                "        )\n",
                "        \n",
                "        self.intent_chain = self.intent_prompt | llm | parser\n",
                "        self.response_chain = self.response_prompt | llm | parser\n",
                "    \n",
                "    def process_turn(self, user_message):\n",
                "        # Extract intent and entities\n",
                "        intent_info = self.intent_chain.invoke({\n",
                "            \"user_message\": user_message,\n",
                "            \"history\": str(self.conversation_state[\"history\"])\n",
                "        })\n",
                "        \n",
                "        # Update state\n",
                "        self.conversation_state[\"history\"].append({\n",
                "            \"user\": user_message,\n",
                "            \"intent\": intent_info\n",
                "        })\n",
                "        \n",
                "        # Generate response\n",
                "        response = self.response_chain.invoke({\n",
                "            \"user_message\": user_message,\n",
                "            \"intent_info\": intent_info,\n",
                "            \"history\": str(self.conversation_state[\"history\"][:-1]),  # Exclude current\n",
                "            \"user_info\": str(self.conversation_state[\"user_info\"])\n",
                "        })\n",
                "        \n",
                "        # Update history with response\n",
                "        self.conversation_state[\"history\"][-1][\"response\"] = response\n",
                "        \n",
                "        return response\n",
                "\n",
                "# Demo conversation\n",
                "print(\"=== PATTERN 5: Conversational Agent with State ===\")\n",
                "agent = ConversationalAgent()\n",
                "\n",
                "turns = [\n",
                "    \"Hi, I'd like to book a doctor's appointment\",\n",
                "    \"I prefer next Tuesday afternoon\",\n",
                "    \"Yes, that works. My name is Sarah Johnson\"\n",
                "]\n",
                "\n",
                "for i, user_msg in enumerate(turns, 1):\n",
                "    print(f\"\\n--- Turn {i} ---\")\n",
                "    print(f\"User: {user_msg}\")\n",
                "    response = agent.process_turn(user_msg)\n",
                "    print(f\"Agent: {response}\")\n",
                "\n",
                "print(\"\\n=== Final Conversation State ===\")\n",
                "print(f\"Total turns: {len(agent.conversation_state['history'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pattern6-header",
            "metadata": {},
            "source": [
                "## Pattern 6: Code Generation and Refinement\n",
                "\n",
                "This pattern demonstrates iterative code development: requirements → pseudocode → implementation → analysis → refinement.\n",
                "\n",
                "**Use Case**: AI-assisted programming, code generation tools"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "pattern6-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== PATTERN 6: Code Generation and Refinement ===\n",
                        "\n",
                        "=== Pseudocode ===\n",
                        "1. Define a function called findLongestPalindromicSubstring that takes a string as input.\n",
                        "\n",
                        "2. Initialize a variable called longestPalindrome to an empty string.\n",
                        "\n",
                        "3. Create a nested loop to iterate through all possible substrings in the input string:\n",
                        "   - Outer loop: for i from 0 to the length of the input string\n",
                        "   - Inner loop: for j from i+1 to the length of the input string\n",
                        "\n",
                        "4. Inside the nested loop, extract the current substring using string slicing:\n",
                        "   - substring = input_string[i:j+1]\n",
                        "\n",
                        "5. Check if the current substring is a palindrome:\n",
                        "   - Create a helper function called isPalindrome that takes a string as input and returns a boolean value indicating whether it is a palindrome or not.\n",
                        "   - If isPalindrome(substring) returns true and the length of the current substring is greater than the length of the longestPalindrome, update longestPalindrome to be the current substring.\n",
                        "\n",
                        "6. After the nested loop completes, return the longestPalindrome.\n",
                        "\n",
                        "7. Define the helper function isPalindrome:\n",
                        "   - Initialize two pointers, left and right, pointing to the start and end of the input string respectively.\n",
                        "   - While left < right, check if the characters at the left and right pointers are equal.\n",
                        "   - If they are not equal, return false.\n",
                        "   - If the loop completes without finding any unequal characters, return true indicating that the input string is a palindrome.\n",
                        "\n",
                        "8. Call the findLongestPalindromicSubstring function with the given input string to find the longest palindromic substring.\n",
                        "\n",
                        "=== Initial Code ===\n",
                        "```python\n",
                        "def findLongestPalindromicSubstring(input_string):\n",
                        "    \"\"\"\n",
                        "    Find the longest palindromic substring in the given input string.\n",
                        "\n",
                        "    Args:\n",
                        "    input_string (str): The input string to search for palindromic substrings.\n",
                        "\n",
                        "    Returns:\n",
                        "    str: The longest palindromic substring found in the input string.\n",
                        "    \"\"\"\n",
                        "\n",
                        "    def isPalindrome(s):\n",
                        "        \"\"\"\n",
                        "        Check if the input string is a palindrome.\n",
                        "\n",
                        "        Args:\n",
                        "        s (str): The input string to check for palindrome.\n",
                        "\n",
                        "        Returns:\n",
                        "        bool: True if the input string is a palindrome, False otherwise.\n",
                        "        \"\"\"\n",
                        "        left, right = 0, len(s) - 1\n",
                        "        while left < right:\n",
                        "            if s[left] != s[right]:\n",
                        "                return False\n",
                        "            left += 1\n",
                        "            right -= 1\n",
                        "        return True\n",
                        "\n",
                        "    longestPalindrome = \"\"\n",
                        "\n",
                        "    for i in range(len(input_string)):\n",
                        "        for j in range(i + 1, len(input_string)):\n",
                        "            substring = input_string[i:j+1]\n",
                        "            if isPalindrome(substring) and len(substring) > len(longestPalindrome):\n",
                        "                longestPalindrome = substring\n",
                        "\n",
                        "    return longestPalindrome\n",
                        "\n",
                        "# Test the function with an example input\n",
                        "input_string = \"babad\"\n",
                        "result = findLongestPalindromicSubstring(input_string)\n",
                        "print(result)\n",
                        "```\n",
                        "Output:\n",
                        "```\n",
                        "aba\n",
                        "```\n",
                        "\n",
                        "=== Code Analysis ===\n",
                        "Specific issues found:\n",
                        "1. Bugs or logical errors:\n",
                        "   - The `isPalindrome` function does not handle empty strings correctly. It should return True for empty strings as they are considered palindromes.\n",
                        "   - The inner loop in the `findLongestPalindromicSubstring` function should start from `i` instead of `i + 1` to include single characters as potential palindromes.\n",
                        "\n",
                        "2. Missing edge case handling:\n",
                        "   - The code does not handle cases where the input string is empty. It should return an appropriate message or handle this edge case gracefully.\n",
                        "\n",
                        "3. Performance issues:\n",
                        "   - The current approach has a time complexity of O(n^3) due to the nested loops and checking each substring for palindrome. This can be optimized to O(n^2) by using dynamic programming or a different algorithm.\n",
                        "\n",
                        "4. Code style improvements:\n",
                        "   - The `isPalindrome` function can be simplified by using Python's slicing feature to check for palindromes.\n",
                        "   - Adding docstrings to the inner functions for better readability and documentation.\n",
                        "\n",
                        "=== Refined Code ===\n",
                        "Improved code:\n",
                        "\n",
                        "```python\n",
                        "def findLongestPalindromicSubstring(input_string):\n",
                        "    \"\"\"\n",
                        "    Find the longest palindromic substring in the given input string.\n",
                        "\n",
                        "    Args:\n",
                        "    input_string (str): The input string to search for palindromic substrings.\n",
                        "\n",
                        "    Returns:\n",
                        "    str: The longest palindromic substring found in the input string.\n",
                        "    \"\"\"\n",
                        "\n",
                        "    def isPalindrome(s):\n",
                        "        \"\"\"\n",
                        "        Check if the input string is a palindrome.\n",
                        "\n",
                        "        Args:\n",
                        "        s (str): The input string to check for palindrome.\n",
                        "\n",
                        "        Returns:\n",
                        "        bool: True if the input string is a palindrome, False otherwise.\n",
                        "        \"\"\"\n",
                        "        return s == s[::-1]\n",
                        "\n",
                        "    if not input_string:\n",
                        "        return \"Input string is empty.\"\n",
                        "\n",
                        "    longestPalindrome = \"\"\n",
                        "\n",
                        "    for i in range(len(input_string)):\n",
                        "        for j in range(i, len(input_string)):\n",
                        "            substring = input_string[i:j+1]\n",
                        "            if isPalindrome(substring) and len(substring) > len(longestPalindrome):\n",
                        "                longestPalindrome = substring\n",
                        "\n",
                        "    return longestPalindrome\n",
                        "\n",
                        "# Test the function with an example input\n",
                        "input_string = \"babad\"\n",
                        "result = findLongestPalindromicSubstring(input_string)\n",
                        "print(result)\n",
                        "```\n",
                        "\n",
                        "Output:\n",
                        "```\n",
                        "aba\n",
                        "``` \n",
                        "\n",
                        "Improvements made:\n",
                        "1. Fixed the bug in the `isPalindrome` function to correctly handle empty strings as palindromes.\n",
                        "2. Updated the inner loop in the `findLongestPalindromicSubstring` function to start from `i` to include single characters as potential palindromes.\n",
                        "3. Added a check for empty input strings and return an appropriate message.\n",
                        "4. Simplified the `isPalindrome` function using Python's slicing feature.\n",
                        "5. Improved code readability by adding docstrings to the inner functions.\n",
                        "\n",
                        "=== Final Code with Docs and Tests ===\n",
                        "```python\n",
                        "import pytest\n",
                        "\n",
                        "def findLongestPalindromicSubstring(input_string):\n",
                        "    \"\"\"\n",
                        "    Find the longest palindromic substring in the given input string.\n",
                        "\n",
                        "    Args:\n",
                        "    input_string (str): The input string to search for palindromic substrings.\n",
                        "\n",
                        "    Returns:\n",
                        "    str: The longest palindromic substring found in the input string.\n",
                        "    \"\"\"\n",
                        "\n",
                        "    def isPalindrome(s):\n",
                        "        \"\"\"\n",
                        "        Check if the input string is a palindrome.\n",
                        "\n",
                        "        Args:\n",
                        "        s (str): The input string to check for palindrome.\n",
                        "\n",
                        "        Returns:\n",
                        "        bool: True if the input string is a palindrome, False otherwise.\n",
                        "        \"\"\"\n",
                        "        return s == s[::-1]\n",
                        "\n",
                        "    if not input_string:\n",
                        "        return \"Input string is empty.\"\n",
                        "\n",
                        "    longestPalindrome = \"\"\n",
                        "\n",
                        "    for i in range(len(input_string)):\n",
                        "        for j in range(i, len(input_string)):\n",
                        "            substring = input_string[i:j+1]\n",
                        "            if isPalindrome(substring) and len(substring) > len(longestPalindrome):\n",
                        "                longestPalindrome = substring\n",
                        "\n",
                        "    return longestPalindrome\n",
                        "\n",
                        "def test_findLongestPalindromicSubstring():\n",
                        "    # Test with a simple palindrome\n",
                        "    assert findLongestPalindromicSubstring(\"babad\") == \"aba\"\n",
                        "    \n",
                        "    # Test with an empty string\n",
                        "    assert findLongestPalindromicSubstring(\"\") == \"Input string is empty.\"\n",
                        "    \n",
                        "    # Test with a string that has no palindromic substring\n",
                        "    assert findLongestPalindromicSubstring(\"xyz\") == \"x\"\n",
                        "\n",
                        "    # Test with a string that has multiple palindromic substrings\n",
                        "    assert findLongestPalindromicSubstring(\"racecar\") == \"racecar\"\n",
                        "\n",
                        "    # Test with a string that has a single character\n",
                        "    assert findLongestPalindromicSubstring(\"a\") == \"a\"\n",
                        "\n",
                        "    # Test with a string that has all characters the same\n",
                        "    assert findLongestPalindromicSubstring(\"zzzzzz\") == \"zzzzzz\"\n",
                        "\n",
                        "    # Test with a string that has spaces\n",
                        "    assert findLongestPalindromicSubstring(\"a b c dcdc b a\") == \" dcdc \"\n",
                        "\n",
                        "    # Test with a string that has special characters\n",
                        "    assert findLongestPalindromicSubstring(\"a!b!cdc!b!a\") == \"b!cdc!b\"\n",
                        "\n",
                        "    # Test with a string that has numbers\n",
                        "    assert findLongestPalindromicSubstring(\"12321\") == \"12321\"\n",
                        "\n",
                        "    # Test with a string that has a mix of characters\n",
                        "    assert findLongestPalindromicSubstring(\"a!b1c2dcdc3b4a\") == \"b1c2dcdc3b\"\n",
                        "\n",
                        "    # Test with a long string\n",
                        "    assert findLongestPalindromicSubstring(\"abacdfgdcaba\") == \"aba\"\n",
                        "\n",
                        "if __name__ == \"__main__\":\n",
                        "    pytest.main()\n",
                        "```\n"
                    ]
                }
            ],
            "source": [
                "# Pattern 6: Code Generation and Refinement\n",
                "# 5-step chain: requirements -> pseudocode -> code -> analysis -> refinement\n",
                "\n",
                "# Step 1: Understand requirements and generate pseudocode\n",
                "prompt_pseudocode = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Based on this requirement, write detailed pseudocode:\n",
                "\n",
                "Requirement: {requirement}\n",
                "\n",
                "Break down the logic step-by-step in pseudocode format.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 2: Generate initial code\n",
                "prompt_initial_code = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Convert this pseudocode into Python code:\n",
                "\n",
                "{pseudocode}\n",
                "\n",
                "Original requirement: {requirement}\n",
                "\n",
                "Provide clean, well-structured Python code with docstrings.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 3: Analyze for errors and improvements\n",
                "prompt_analyze_code = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Analyze this code for potential errors, edge cases, and improvements:\n",
                "\n",
                "{code}\n",
                "\n",
                "List specific issues found:\n",
                "1. Bugs or logical errors\n",
                "2. Missing edge case handling\n",
                "3. Performance issues\n",
                "4. Code style improvements\"\"\"\n",
                ")\n",
                "\n",
                "# Step 4: Refine the code\n",
                "prompt_refine_code = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Refine this code based on the identified issues:\n",
                "\n",
                "Original code:\n",
                "{code}\n",
                "\n",
                "Issues to address:\n",
                "{issues}\n",
                "\n",
                "Provide the improved version of the code.\"\"\"\n",
                ")\n",
                "\n",
                "# Step 5: Add documentation and tests\n",
                "prompt_add_docs = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Add comprehensive docstrings and 2-3 unit test cases for this code:\n",
                "\n",
                "{refined_code}\n",
                "\n",
                "Include:\n",
                "- Function/class docstrings\n",
                "- Pytest-style test cases\"\"\"\n",
                ")\n",
                "\n",
                "# Build code generation workflow\n",
                "pseudocode_chain = prompt_pseudocode | llm | parser\n",
                "code_chain = prompt_initial_code | llm | parser\n",
                "analyze_chain = prompt_analyze_code | llm | parser\n",
                "refine_chain = prompt_refine_code | llm | parser\n",
                "docs_chain = prompt_add_docs | llm | parser\n",
                "\n",
                "def code_generation_workflow(requirement):\n",
                "    # Generate pseudocode\n",
                "    pseudocode = pseudocode_chain.invoke({\"requirement\": requirement})\n",
                "    print(\"\\n=== Pseudocode ===\")\n",
                "    print(pseudocode)\n",
                "    \n",
                "    # Generate initial code\n",
                "    code = code_chain.invoke({\n",
                "        \"pseudocode\": pseudocode,\n",
                "        \"requirement\": requirement\n",
                "    })\n",
                "    print(\"\\n=== Initial Code ===\")\n",
                "    print(code)\n",
                "    \n",
                "    # Analyze for issues\n",
                "    issues = analyze_chain.invoke({\"code\": code})\n",
                "    print(\"\\n=== Code Analysis ===\")\n",
                "    print(issues)\n",
                "    \n",
                "    # Refine code\n",
                "    refined = refine_chain.invoke({\n",
                "        \"code\": code,\n",
                "        \"issues\": issues\n",
                "    })\n",
                "    print(\"\\n=== Refined Code ===\")\n",
                "    print(refined)\n",
                "    \n",
                "    # Add documentation\n",
                "    final = docs_chain.invoke({\"refined_code\": refined})\n",
                "    print(\"\\n=== Final Code with Docs and Tests ===\")\n",
                "    print(final)\n",
                "    \n",
                "    return final\n",
                "\n",
                "print(\"=== PATTERN 6: Code Generation and Refinement ===\")\n",
                "requirement = \"Create a function that finds the longest palindromic substring in a given string\"\n",
                "result = code_generation_workflow(requirement)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pattern7-header",
            "metadata": {},
            "source": [
                "## Pattern 7: Multimodal and Multi-step Reasoning\n",
                "\n",
                "This pattern demonstrates processing information from multiple modalities (image + text + structured data).\n",
                "\n",
                "**Use Case**: Invoice processing, document understanding, image-text analysis\n",
                "\n",
                "**Note**: This example uses GPT-4 Vision capabilities. Make sure you have access to vision-enabled models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "pattern7-code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== PATTERN 7: Multimodal and Multi-step Reasoning ===\n",
                        "\n",
                        "=== Step 1: Extracting text from invoice image ===\n",
                        "**Invoice Information:**\n",
                        "\n",
                        "- **Title:** ACME Corp Invoice\n",
                        "\n",
                        "- **Company Name:** ACME Corp\n",
                        "- **Address:** 456 Business Avenue, Springfield, IL 62701\n",
                        "- **Contact Email:** info@gmail.com\n",
                        "\n",
                        "- **Invoice Number:** #12345\n",
                        "- **Date:** 2024-01-15\n",
                        "\n",
                        "**Bill To:**\n",
                        "\n",
                        "- **Name:** John Smith\n",
                        "- **Address:** 123 Main Street, New York, NY 10001\n",
                        "\n",
                        "**Items:**\n",
                        "\n",
                        "1. **Item:** Laptop Computer\n",
                        "   - **Quantity:** 2\n",
                        "   - **Unit Price:** $1,200\n",
                        "   - **Total:** $2,400\n",
                        "\n",
                        "2. **Item:** Wireless Mouse\n",
                        "   - **Quantity:** 5\n",
                        "   - **Unit Price:** $25\n",
                        "   - **Total:** $125\n",
                        "\n",
                        "**Summary:**\n",
                        "\n",
                        "- **Subtotal:** $2,525\n",
                        "- **Tax (8%):** $202\n",
                        "- **Total Amount Due:** $2,727\n",
                        "\n",
                        "**Footer:**\n",
                        "\n",
                        "- **Message:** Thank you for your business! Payment due within 30 days.\n",
                        "\n",
                        "=== Step 2: Linking extracted text with labels ===\n",
                        "- Invoice Number: #12345\n",
                        "- Date: 2024-01-15\n",
                        "- Customer:\n",
                        "  - Name: John Smith\n",
                        "  - Address: 123 Main Street, New York, NY 10001\n",
                        "- Items:\n",
                        "  1. \n",
                        "     - Item: Laptop Computer\n",
                        "     - Quantity: 2\n",
                        "     - Unit Price: $1,200\n",
                        "     - Total: $2,400\n",
                        "  2. \n",
                        "     - Item: Wireless Mouse\n",
                        "     - Quantity: 5\n",
                        "     - Unit Price: $25\n",
                        "     - Total: $125\n",
                        "- Total Amount: $2,727\n",
                        "\n",
                        "=== Step 3: Interpreting with business rules ===\n",
                        "1. The total amount is $2,727, which falls in the range of $1000-$5000 for both existing and new customers.\n",
                        "2. The required action is Director review for this invoice.\n",
                        "3. No special notes or flags.\n"
                    ]
                }
            ],
            "source": [
                "# Pattern 7: Multimodal and Multi-step Reasoning\n",
                "# 3-step chain: extract image text -> link labels -> interpret with table\n",
                "\n",
                "import base64\n",
                "from pathlib import Path\n",
                "\n",
                "# For vision capabilities, use GPT-4 Vision\n",
                "vision_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
                "\n",
                "# Load invoice image\n",
                "image_path = Path(\"../assets/invoice_sample.png\")\n",
                "\n",
                "# Step 1: Extract text from image\n",
                "def encode_image(image_path):\n",
                "    with open(image_path, \"rb\") as image_file:\n",
                "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
                "\n",
                "def extract_text_from_image(image_path):\n",
                "    base64_image = encode_image(image_path)\n",
                "    \n",
                "    prompt = ChatPromptTemplate.from_messages([\n",
                "        (\"user\", [\n",
                "            {\"type\": \"text\", \"text\": \"Extract all text from this invoice image. List each piece of information clearly.\"},\n",
                "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
                "        ])\n",
                "    ])\n",
                "    \n",
                "    chain = prompt | vision_llm | parser\n",
                "    return chain.invoke({})\n",
                "\n",
                "# Step 2: Link extracted text with labels\n",
                "prompt_link_labels = ChatPromptTemplate.from_template(\n",
                "    \"\"\"From the extracted invoice text, identify and label these key fields:\n",
                "\n",
                "Extracted text:\n",
                "{extracted_text}\n",
                "\n",
                "Create a labeled structure:\n",
                "- Invoice Number: \n",
                "- Date:\n",
                "- Customer:\n",
                "- Items:\n",
                "- Total Amount:\n",
                "\"\"\"\n",
                ")\n",
                "\n",
                "# Step 3: Interpret using business rules table\n",
                "prompt_interpret = ChatPromptTemplate.from_template(\n",
                "    \"\"\"Using this labeled invoice data and business rules, determine the required action:\n",
                "\n",
                "Labeled Data:\n",
                "{labeled_data}\n",
                "\n",
                "Business Rules Table:\n",
                "| Total Amount | Customer Type | Action |\n",
                "|--------------|---------------|--------|\n",
                "| < $1000      | Any           | Auto-approve |\n",
                "| $1000-$5000  | Existing      | Manager review |\n",
                "| $1000-$5000  | New           | Director review |\n",
                "| > $5000      | Any           | Director approval required |\n",
                "\n",
                "Determine:\n",
                "1. Which rule applies\n",
                "2. Required action\n",
                "3. Any special notes or flags\n",
                "\"\"\"\n",
                ")\n",
                "\n",
                "# Build multimodal workflow\n",
                "link_chain = prompt_link_labels | llm | parser  \n",
                "interpret_chain = prompt_interpret | llm | parser\n",
                "\n",
                "def multimodal_workflow(image_path):\n",
                "    # Step 1: Extract text from image\n",
                "    print(\"\\n=== Step 1: Extracting text from invoice image ===\")\n",
                "    extracted_text = extract_text_from_image(image_path)\n",
                "    print(extracted_text)\n",
                "    \n",
                "    # Step 2: Link with labels\n",
                "    print(\"\\n=== Step 2: Linking extracted text with labels ===\")\n",
                "    labeled_data = link_chain.invoke({\"extracted_text\": extracted_text})\n",
                "    print(labeled_data)\n",
                "    \n",
                "    # Step 3: Interpret with business rules\n",
                "    print(\"\\n=== Step 3: Interpreting with business rules ===\")\n",
                "    final_decision = interpret_chain.invoke({\"labeled_data\": labeled_data})\n",
                "    print(final_decision)\n",
                "    \n",
                "    return final_decision\n",
                "\n",
                "print(\"=== PATTERN 7: Multimodal and Multi-step Reasoning ===\")\n",
                "if image_path.exists():\n",
                "    result = multimodal_workflow(image_path)\n",
                "else:\n",
                "    print(f\"Image not found at {image_path}. Please ensure the invoice_sample.png exists in the assets folder.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "This notebook demonstrated 7 comprehensive prompt chaining patterns:\n",
                "\n",
                "1. **Information Processing Workflows** - Multi-step document analysis pipeline\n",
                "2. **Complex Query Answering** - Breaking down and synthesizing research questions  \n",
                "3. **Data Extraction and Transformation** - Iterative extraction with validation\n",
                "4. **Content Generation Workflows** - Progressive content creation\n",
                "5. **Conversational Agents with State** - Context-aware multi-turn dialogues\n",
                "6. **Code Generation and Refinement** - Iterative code development\n",
                "7. **Multimodal and Multi-step Reasoning** - Processing images, text, and structured data\n",
                "\n",
                "Each pattern demonstrates how prompt chaining enables complex AI workflows by breaking tasks into manageable, sequential steps."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "asd",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
