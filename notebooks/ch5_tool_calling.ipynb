{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 5: Tool Calling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Key Takeaways:\n",
                "- **Tool Calling** (or Function Calling) gives LLMs access to external tools (APIs, databases, functions).\n",
                "- The model can decide *when* to call a tool and *what arguments* to pass based on the user query.\n",
                "- This pattern bridges the gap between the static knowledge of the model and the dynamic, real-time world."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Heuristic: *Give the model hands.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup and Initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f036b01",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import getpass\n",
                "import asyncio\n",
                "import nest_asyncio\n",
                "from dotenv import load_dotenv\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.tools import tool as langchain_tool\n",
                "from langchain_classic.agents import create_tool_calling_agent, AgentExecutor\n",
                "\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c29eef27",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Configuration ---\n",
                "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
                "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")\n",
                "\n",
                "try:\n",
                "    # A model with function/tool calling capabilities is required.\n",
                "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
                "    print(f\"‚úÖ Language model initialized: {llm.model}\")\n",
                "except Exception as e:\n",
                "    print(f\"üõë Error initializing language model: {e}\")\n",
                "    llm = None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2da12817",
            "metadata": {},
            "source": [
                "## Define a Tool\n",
                "\n",
                "We define a tool `search_information` that the agent can use to retrieve specific simulated data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c800b36f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Define a Tool ---\n",
                "@langchain_tool\n",
                "def search_information(query: str) -> str:\n",
                "    \"\"\"\n",
                "    Provides factual information on a given topic. Use this tool to\n",
                "    find answers to phrases like 'capital of France' or 'weather in London?'.\n",
                "    \"\"\"\n",
                "    print(f\"\\n--- Ô∏è Tool Called: search_information with query: '{query}' ---\")\n",
                "    \n",
                "    # Simulate a search tool with a dictionary of predefined results.\n",
                "    simulated_results = {\n",
                "        \"weather in london\": \"The weather in London is currently cloudy with a temperature of 15¬∞C.\",\n",
                "        \"capital of france\": \"The capital of France is Paris.\",\n",
                "        \"population of earth\": \"The estimated population of Earth is around 8 billion people.\",\n",
                "        \"tallest mountain\": \"Mount Everest is the tallest mountain above sea level.\",\n",
                "        \"default\": f\"Simulated search result for '{query}': No specific information found, but the topic seems interesting.\"\n",
                "    }\n",
                "    \n",
                "    result = simulated_results.get(query.lower(), simulated_results[\"default\"])\n",
                "    print(f\"--- TOOL RESULT: {result} ---\")\n",
                "    return result\n",
                "\n",
                "tools = [search_information]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a4d157db",
            "metadata": {},
            "source": [
                "## Create Agent\n",
                "\n",
                "Construct the agent with the tools and the LLM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5301d2e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Create a Tool-Calling Agent ---\n",
                "if llm:\n",
                "    # This prompt template requires an `agent_scratchpad` placeholder for the agent's internal steps.\n",
                "    agent_prompt = ChatPromptTemplate.from_messages([\n",
                "        (\"system\", \"You are a helpful assistant.\"),\n",
                "        (\"human\", \"{input}\"),\n",
                "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
                "    ])\n",
                "\n",
                "    # Create the agent, binding the LLM, tools, and prompt together.\n",
                "    agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
                "\n",
                "    # AgentExecutor is the runtime that invokes the agent and executes the chosen tools.\n",
                "    agent_executor = AgentExecutor(agent=agent, verbose=True, tools=tools)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8fdf7086",
            "metadata": {},
            "source": [
                "## Execution\n",
                "\n",
                "We run the agent with several queries in parallel to demonstrate its ability to pick the right tool (or no tool)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5dcf906",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def run_agent_with_tool(query: str):\n",
                "    \"\"\"Invokes the agent executor with a query and prints the final response.\"\"\"\n",
                "    print(f\"\\n--- üèÉ Running Agent with Query: '{query}' ---\")\n",
                "    try:\n",
                "        response = await agent_executor.ainvoke({\"input\": query})\n",
                "        print(\"\\n--- ‚úÖ Final Agent Response ---\")\n",
                "        print(response[\"output\"])\n",
                "    except Exception as e:\n",
                "        print(f\"\\nüõë An error occurred during agent execution: {e}\")\n",
                "\n",
                "async def main():\n",
                "    \"\"\"Runs all agent queries concurrently.\"\"\"\n",
                "    tasks = [\n",
                "        run_agent_with_tool(\"What is the capital of France?\"),\n",
                "        run_agent_with_tool(\"What's the weather like in London?\"),\n",
                "        run_agent_with_tool(\"Tell me something about dogs.\") # Should trigger the default tool response or no tool?\n",
                "    ]\n",
                "    await asyncio.gather(*tasks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9b58a6fd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# nest_asyncio.apply() # Not needed in Jupyter if using await main()\n",
                "await main()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "By equipping the agent with tools, we transform it from a passive text generator into an active problem solver capable of performing tasks and retrieving external information."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "asd",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
